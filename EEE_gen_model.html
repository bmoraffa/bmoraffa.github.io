<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>EEE: Machine Learning for Signals, Information, and Data</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Bahman Moraffah</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="blog.html">Blog</a></div>
<div class="menu-item"><a href="tutorials.html">Tutorials</a></div>
<div class="menu-item"><a href="mybook.html">Books</a></div>
<div class="menu-item"><a href="bio.html">Awards</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="presentation.html">Presentations</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-category">How to do Research?</div>
<div class="menu-item"><a href="courses.html">What&nbsp;to&nbsp;Study?</a></div>
<div class="menu-item"><a href="htdr.html">How&nbsp;to&nbsp;Do&nbsp;Research?</a></div>
<div class="menu-category">Links</div>
<div class="menu-item"><a href="https://github.com/bmoraffa">GitHub</a></div>
<div class="menu-item"><a href="https://scholar.google.com">Google&nbsp;Scholar</a></div>
<div class="menu-item"><a href="https://twitter.com/explore">Twitter</a></div>
<div class="menu-category">Classes</div>
<div class="menu-item"><a href="BIM.html">BIM</a></div>
<div class="menu-item"><a href="EEE554.html" class="current">MLSID</a></div>
  <div class="menu-item"><a href="EEE_SID.html" class="current">MLSID</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>EEE:Generative Models for Signal Processing<br /></h1>
<div id="subtitle"><a href="index.html" target=&ldquo;blank&rdquo;>Bahman Moraffah</a>, Fall 2024</div>
</div>
<h2>General Information</h2>
<p>Instructor: Professor <a href="https://bmoraffah.github.io" target=&ldquo;blank&rdquo;>Bahman Moraffah</a><br />
Office: GWC 333<br />
Office Hours: TTh 10:30-11:30 am or by appointment <br />
Class Meet: TTh 12:00-1:15 pm in SS105 <br />
Email: <a href="mailto:bahman.moraffah@asu.edu" target=&ldquo;blank&rdquo;>bahman.moraffah@asu.edu</a></p>
<h2>Course Description</h2>
<p>This graduate-level course explores deep generative models with an emphasis on diffusion models. The course includes theoretical foundations, practical implementations, and applications in signal processing. Topics cover various generative models, the mathematics needed for these models, and their applications.</p>
<h2>Course Policies</h2>
<ol>
<li><p><b>Prerequisites:</b></p>
<ol>
<li><p>Basic knowledge of linear algebra, probability, and programming.</p>
</li>
<li><p>Prior coursework in signal processing or data analysis is beneficial but not required.</p>
</li>
</ol>
</li>
<li><p><b>Collaboration:</b> You are encouraged to work on homework problems in study groups of no more than 3 people; however, you must always write up the solutions on your own, and you must never read or copy the solutions of other students. Similarly, you may use books or online resources to help solve homework problems, but you must always credit all such sources in your writeup and you must never copy material verbatim. Offering and accepting solutions from others is an act of plagiarism, which is a serious offense and all involved parties will be penalized according to the Academic Honesty Policy.</p>
</li>
<li><p><b>Quizzes and Exams:</b> All quizzes and exams are closed books and notes, a single letter-sized notes sheet (front and back) is allowed.</p>
</li>
<li><p><b>Scribe:</b> We need volunteers to take notes each class, type them up, and send them to me so they can be uploaded for the entire class. Each student can scribe at most 2 lectures. Scribing is NOT mandatory but it is highly encouraged. To get extra credit, you must take notes and type them in the provided template. Extra points are at the instructorâ€™s discretion and depend on the student's effort. You can download the template <a href="template.tex" target=&ldquo;blank&rdquo;>here</a>.</p>
</li>
</ol>
<h2>Syllabus</h2>
<ul>
<li><p>Week 1: Introduction to Generative Models</p>
<ul>
<li><p>Overview of Generative Models</p></li>
<li><p>Mathematical Foundations</p></li>
</ul>
</li>
<li><p>Week 2: Fundamental Generative Models</p>
<ul>
<li><p>Variational Autoencoders (VAEs)</p></li>
<li><p>Generative Adversarial Networks (GANs)</p></li>
<li><p>Flow-based Models</p></li>
</ul>
</li>
<li><p>Week 3: Diffusion Models I</p>
<ul>
<li><p>Introduction to Diffusion Models</p></li>
<li><p>Mathematical Foundations of Diffusion Models</p></li>
</ul>
</li>
<li><p>Week 4: Diffusion Models II</p>
<ul>
<li><p>Training Diffusion Models</p></li>
<li><p>Sampling Techniques</p></li>
</ul>
</li>
<li><p>Week 5: Advanced Topics in Diffusion Models</p>
<ul>
<li><p>Accelerating Diffusion Models</p></li>
<li><p>Improving Image Quality in Diffusion Models</p></li>
</ul>
</li>
<li><p>Week 6: Project Presentations</p>
<ul>
<li><p>Student project presentations</p></li>
<li><p>Discussion and feedback</p></li>
</ul>
</li>
<li><p>Week 7: Mathematics for Generative Models</p>
<ul>
<li><p>Advanced Probability and Statistics</p></li>
<li><p>Optimization Techniques</p></li>
</ul>
</li>
<li><p>Week 8: Other Generative Models</p>
<ul>
<li><p>Energy-based Models (EBMs)</p></li>
<li><p>Autoregressive Models</p></li>
</ul>
</li>
<li><p>Week 9: Applications in Signal Processing I</p>
<ul>
<li><p>Generative Models for Signal Processing</p></li>
<li><p>Case Studies and Applications</p></li>
</ul>
</li>
<li><p>Week 10: Applications in Signal Processing II</p>
<ul>
<li><p>Specific applications in biomedical signal processing</p></li>
<li><p>Case studies on speech and audio processing</p></li>
</ul>
</li>
<li><p>Week 11: Review and Future Directions</p>
<ul>
<li><p>Recent Advances and Research Directions</p></li>
<li><p>Student Presentations and Discussions</p></li>
</ul>
</li>
<li><p>Week 12: Course Review and Q&A</p>
<ul>
<li><p>Summary of key concepts</p></li>
<li><p>Exam preparation tips and practice questions</p></li>
</ul>
</li>
</ul>
<h2>Textbooks</h2>
<ul>
<li><p>"Deep Learning" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville</p>
</li>
<li><p>"Probabilistic Machine Learning: Advanced Topics" by Kevin P. Murphy</p>
</li>
<li><p>"Denoising Diffusion Probabilistic Models" by Jonathan Ho, Ajay Jain, and Pieter Abbeel (paper)</p>
</li>
<li><p>"Score-Based Generative Modeling through Stochastic Differential Equations" by Yang Song, Stefano Ermon (paper)</p>
</li>
</ul>
<h2>Assessment</h2>
<ul>
<li><p>Quizzes and Class Participation: 10%</p>
</li>
<li><p>Homework: 20%</p>
</li>
<li><p>Midterm: 20%</p>
</li>
<li><p>Project: 30%</p>
</li>
<li><p>Final Exam: 20%</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2024-07-26, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
